3.1 Solution Design

The proposed LaundryPOS solution is designed as a two‑platform architecture that separates administrative control from day‑to‑day operations while sharing a common backend. It consists of a web-based Admin portal (LaundryPos(ADMIN)) and a cross‑platform Staff mobile application (LaundryPOS(STAFF)), both connected to a centralized LaundryPOS API. This architecture ensures that all branches, users, and transactions operate on a single, consistent data source with real‑time synchronization, secure access control, and scalable performance.

The LaundryPos(ADMIN) platform is implemented as a modern single-page web application. It is intended for owners and managers to configure and oversee the entire laundry business. Through this portal, administrators can manage user accounts and roles, define services and pricing, configure discounts and promotions, maintain branch and machine profiles, and access financial reports and analytics. The interface emphasizes data‑driven dashboards, configurable filters, and exportable reports to support monitoring, auditing, and decision‑making. Security is enforced through authentication and role-based authorization, ensuring that only authorized personnel can access sensitive configuration and financial data.

The LaundryPOS(STAFF) platform is developed as a cross‑platform mobile application suitable for Android devices commonly used at counters and by riders. It is optimized for fast, guided workflows that support front‑line staff in handling customers and orders efficiently. Core functions include customer registration, order intake, selection of services and discounts, status updates throughout the laundry process, payment recording, and receipt generation. For delivery-oriented operations, the app also supports assignment and tracking of pickup and delivery tasks. The user interface is designed to be simple, clear, and error‑resistant to reduce training time and operational mistakes.

Both platforms communicate with a shared LaundryPOS API, which exposes standardized endpoints for authentication, customer and order management, service and discount configuration, and reporting. All actions performed in the Staff app are immediately reflected in the Admin portal, allowing management to monitor operations in real time. This integrated solution design provides a clear separation of concerns—administrative configuration in LaundryPos(ADMIN) and operational execution in LaundryPOS(STAFF)—while maintaining a unified, extensible system that can support future enhancements such as loyalty programs, inventory tracking, and third‑party integrations.

3.5 Integration Strategies

3.5.1 API Integrations and Interactions

The LaundryPOS system uses a set of RESTful APIs to coordinate communication between the Admin web application, the Staff mobile application, and internal backend services. All APIs are exposed under the /api base path, use HTTPS in production, and exchange data in JSON format. Each request typically carries authentication credentials in the form of tokens, and responses return HTTP status codes, messages, and structured payloads that can be directly consumed by the client applications.

1. Authentication and Authorization API (AuthRoutes)
   This API handles login, logout, token generation, password reset, and verification code flows for both LaundryPos(ADMIN) and LaundryPOS(STAFF). The main inputs are user credentials or existing tokens, and the outputs are access tokens, optional refresh tokens, and user role information. These tokens are attached to subsequent requests from both applications so that the backend can enforce role-based access control on every protected endpoint.

2. Customer Management API (CustomerRoutes)
   This API is responsible for registering new customers, updating customer details, and retrieving customer profiles and histories. Typical inputs include customer identifiers, names, contact information, and optional notes or preferences; outputs include stored customer records and lists of associated orders and transactions. The Staff app uses this API during intake and order creation, while the Admin portal uses it for customer lookup, issue resolution, and analytics.

3. Order and Transaction API (OrderRoutes)
   This API manages the full lifecycle of laundry orders. It receives order creation requests from the Staff app containing the customer reference, selected services, quantities, timestamps, and payment-related data, and responds with order identifiers, computed totals, and initial status. It also supports updates for changing order status (for example, from received to washing, drying, folding, ready for pickup, or delivered), modifying items, applying discounts or surcharges, and marking payments as completed. Both Admin and Staff applications call this API to view and update order progress in real time.

4. Service, Discount, and Pricing APIs (ServiceRoutes, DiscountRoutes)
   These APIs allow the Admin portal to define and maintain the catalog of laundry services, base prices, and discount rules, while the Staff app reads this data when creating or updating orders. Inputs for Admin operations include service names, categories, prices, and discount conditions; outputs are the current list of active services and rules. When Staff users select services in the app, the frontend calls these APIs (or receives pre-fetched data) to compute itemized prices and final totals consistently with the business rules configured by management.

5. Employee, Station, and RBAC APIs (EmployeeRoutes, StationRoutes, RBACRoutes)
   These APIs manage employee accounts, workstations or stations, and role-based access control. Inputs include employee profiles, role assignments, station definitions, and permission configurations; outputs include confirmed records and effective role and permission mappings. The Admin portal uses these APIs to control who can access sensitive features such as reports, backups, or discount overrides, while the Staff app relies on them indirectly through tokens that embed the user’s permissions.

6. Dashboard, Reporting, and Audit APIs (DashboardRoutes, ReportRoutes, AuditLogRoutes)
   These APIs aggregate transactional data to produce dashboards and detailed reports for management. Inputs usually consist of filters such as date ranges, branches, services, and employee identifiers; outputs include metrics like daily sales, order counts, average processing times, and revenue per branch or service. The Admin portal calls these endpoints to render charts, tables, and exportable reports, while audit log endpoints record and expose sensitive changes (for example, role changes, discount updates, or manual adjustments) for accountability.

7. Expense and System Setting APIs (ExpenseRoutes, SystemSettingRoutes)
   These APIs support configuration of operating expenses and global system settings. Admin users send expense data, categories, and amounts as inputs and receive stored records for use in financial summaries. System setting endpoints accept configuration values such as operating hours, tax rates, notification templates, and backup options and return the effective configuration that other backend modules and clients use to keep behavior consistent across branches.

8. Backup, Upload, and Support APIs (BackupRoutes, UploadRoutes, SupportRoutes)
   Backup APIs allow administrators to trigger database backups, list existing backups, and restore from them when necessary. Upload APIs handle file uploads, such as images or documents, using multipart requests and return file URLs or identifiers that can be stored with orders or profiles. Support APIs provide channels for staff or admins to submit support tickets or feedback, sending input such as descriptions and attachments and returning tracking information and status updates.

9. Notification and Communication APIs (NotificationRoutes, test SMS endpoint)
   Notification APIs accept messages, recipient data, and event types from other parts of the system and forward them to internal services that integrate with external SMS or email providers. Inputs include phone numbers or email addresses, message templates, and dynamic parameters; outputs include delivery status and errors that can be logged or surfaced in the Admin interface. A dedicated test-SMS endpoint is available to verify SMS configuration by sending test messages and returning the provider’s response.

10. Health Check and Monitoring API (/api/health)
    The health endpoint returns structured information about the server’s status, including uptime, memory usage, and database connectivity. It accepts no input parameters and responds with a JSON object describing the current health state and an appropriate HTTP status code. This endpoint is used by monitoring tools or deployment platforms to verify that the LaundryPOS backend is reachable and functioning correctly.

Through these APIs, the Admin web application, the Staff mobile application, and internal backend services interact with each other and with external providers in a controlled, standardized way. Each component sends well-defined requests and processes predictable responses, which simplifies error handling, improves security, and makes the overall LaundryPOS architecture easier to maintain and extend.

3.5.2 Integration of Subject Components

Within the LaundryPOS system, the main subject components—the Admin web application, the Staff mobile application, and the backend services—collaborate closely to deliver end-to-end functionality. The Admin application focuses on configuration, policy definition, and analysis, while the Staff application focuses on operational tasks such as order intake, status updates, and payments. Both client applications depend on shared backend modules such as authentication, order management, service and pricing, customer management, and reporting, which enforce business rules and ensure that all branches follow consistent processes.

This collaboration is made possible through clearly defined interfaces in the form of RESTful APIs and shared data models. For example, when an Admin user updates a discount or price configuration, the change is stored in the backend and immediately affects how the Staff application computes totals for new orders. Similarly, when Staff users update order statuses or record payments, these changes are persisted by the backend and become visible in real time on the Admin dashboards and reports. Dependencies are therefore layered: the user interfaces depend on backend services, backend services depend on the database and infrastructure utilities such as backup, notification, and RBAC, and all components rely on common security and validation mechanisms to keep data accurate and consistent.

3.5.3 Data Flow and Communication

Data within the LaundryPOS system flows along clear pathways between the presentation layer (Admin and Staff interfaces), the application layer (backend services and controllers), and the data layer (database and storage). When a user performs an action—for example, creating an order in the Staff app—the client constructs a JSON request and sends it over HTTPS to the appropriate /api endpoint. The backend validates the request, applies business rules, interacts with the database to read or write records, and then returns a structured response describing the result of the operation. The client then updates its user interface based on this response, such as showing the new order number or updated status.

For read-heavy operations like dashboards, reports, and order tracking, the Admin portal and Staff app issue filtered GET requests that retrieve aggregated or detailed data, which is then displayed in tables, charts, or status views. Communication mechanisms include standard HTTP methods (GET, POST, PUT, PATCH, DELETE), token-based authentication headers, and occasional multipart upload requests for files. Internally, backend modules communicate through function calls and shared models, while external communication with email, SMS, and payment providers uses their respective APIs wrapped by utility services. Throughout these flows, data is transmitted, received, and processed in a way that minimizes duplication, maintains integrity, and ensures that every change made by one component is reliably reflected across the entire system.

4.5 Business Continuity Plan

The LaundryPOS system implements a comprehensive business continuity plan designed to minimize downtime, protect critical data, and ensure rapid recovery from incidents or disasters. This plan encompasses automated backup mechanisms, incident detection and response procedures, and disaster recovery protocols that enable the system to maintain operations or restore service quickly when disruptions occur.

4.5.1 Incident Response Plan

The incident response plan for LaundryPOS addresses various types of incidents that could affect system availability, data integrity, or security. The system includes multiple layers of monitoring and response mechanisms to detect and address issues promptly.

The primary incident detection mechanism is the health check endpoint (/api/health), which continuously monitors server status, memory usage, and database connectivity. This endpoint can be polled by external monitoring tools or deployment platforms to detect when the system becomes unavailable or unhealthy. When an incident is detected—such as database disconnection, excessive memory usage, or server crashes—the monitoring system can trigger alerts to administrators, who can then initiate response procedures.

For authentication and access control incidents, the system provides an emergency recovery mechanism that allows administrators to restore access when they are accidentally locked out. This includes a web-based recovery interface accessible at /emergency-recovery.html, an API endpoint for programmatic recovery, and direct database access scripts. The recovery process uses a secure key mechanism (configurable via environment variables) to prevent unauthorized access while allowing legitimate administrators to restore their permissions quickly.

Error handling and logging are implemented throughout the system to capture incidents as they occur. All API endpoints use try-catch blocks to handle exceptions gracefully, returning structured error responses that include appropriate HTTP status codes and descriptive messages. In development mode, detailed error messages are provided to aid debugging, while in production mode, generic error messages are returned to prevent information leakage. All errors are logged to console and can be captured by logging services for analysis.

Rate limiting and security middleware help prevent incidents caused by malicious activity or system overload. The system implements different rate limits for different types of endpoints: general API endpoints have standard limits, authentication endpoints have stricter limits to prevent brute-force attacks, and sensitive operations like password resets have the most restrictive limits. When rate limits are exceeded, requests are rejected with appropriate error messages, preventing the system from being overwhelmed.

For data integrity incidents, the system uses two-phase locking (2PL) concurrency control for critical operations such as order creation and customer updates. This prevents race conditions and data corruption when multiple users attempt to modify the same resources simultaneously. When conflicts are detected, the system returns clear error messages that guide users to retry their operations.

The incident response workflow typically follows these steps: detection through monitoring or user reports, initial assessment to determine severity and scope, containment to prevent further damage, investigation to identify root causes, resolution through appropriate fixes or workarounds, and post-incident review to document lessons learned and improve future responses. The system's modular architecture and clear separation of concerns make it easier to isolate and address incidents without affecting the entire system.

4.5.2 Disaster Recovery Plan

The disaster recovery plan for LaundryPOS focuses on protecting critical data and enabling rapid restoration of service after catastrophic failures. The cornerstone of this plan is the automated backup system, which creates daily database backups at 2 AM server time and maintains a configurable retention policy (default 30 days) to ensure that multiple recovery points are available.

The backup system uses MongoDB's native tools (mongodump and mongorestore) to create and restore database snapshots. Each backup is stored in a dedicated directory with a timestamped name and includes a metadata file that records the backup timestamp, database name, size, and other relevant information. Backups can be created manually through API endpoints (requiring admin authentication) or automatically through scheduled tasks. The system also provides backup statistics, listing capabilities, and cleanup functions to manage backup storage efficiently.

Backup restoration can be performed through API endpoints or command-line scripts. The restore process supports two modes: standard restore, which merges backup data with existing data (potentially overwriting records with the same identifiers), and drop-and-restore mode, which removes existing collections before restoring, ensuring a clean state. All restore operations require explicit confirmation to prevent accidental data loss. The system validates backup integrity before restoration and provides clear feedback about the restoration process.

For partial recovery scenarios, the backup structure allows administrators to restore specific collections rather than the entire database. This is useful when only certain data has been corrupted or when recovering from user errors that affected specific areas of the system. The backup metadata files help administrators identify which backup to use based on timestamps and other criteria.

The disaster recovery plan also addresses infrastructure failures. The system's architecture, with separate Admin and Staff applications and a centralized backend, allows for independent recovery of components. If the web Admin portal fails, the mobile Staff app can continue operating (assuming backend connectivity), and vice versa. Database failures can be addressed by restoring from backups to a new database instance, and the system's connection configuration allows administrators to point the application to a different database server if needed.

Off-site backup storage is recommended for production deployments to protect against site-wide disasters. While the system stores backups locally by default, administrators can configure scripts to sync backups to cloud storage services such as AWS S3 or Google Cloud Storage. This ensures that backups remain available even if the primary server location is compromised.

The disaster recovery procedures are documented and include step-by-step instructions for common scenarios: full database recovery, partial collection recovery, point-in-time recovery, and emergency access restoration. Regular testing of backup and restore procedures is recommended to ensure that recovery can be performed quickly and accurately when needed. The system's backup API endpoints and command-line tools make it straightforward to verify backup integrity and practice recovery procedures without affecting production data.

In addition to data recovery, the disaster recovery plan addresses service restoration. The health check endpoint helps verify that the system is functioning correctly after recovery, and the modular architecture allows administrators to restart individual components if needed. Environment variable configuration enables administrators to adjust system behavior (such as disabling automated backups or changing retention policies) during recovery operations if necessary.


The LaundryPOS project adopted a layered, API-driven architecture with separate Admin and Staff applications connected to a shared backend. This decision proved successful in terms of clarity of responsibilities, security, and long-term scalability: administrative tasks such as configuration, reporting, and RBAC are clearly separated from day-to-day operational workflows, and both clients can evolve independently while reusing the same backend services. Using RESTful APIs with JSON payloads also made integration straightforward, allowed easy testing with tools like Postman, and simplified debugging when issues arose in communication between components.

However, some architectural choices introduced complexity and trade-offs. Maintaining two client applications (web and mobile) required careful coordination of API contracts and versioning, and any change to data structures or validation rules in the backend had to be reflected in both frontends. The strong focus on security (HTTPS enforcement, rate limiting, RBAC, and environment validation) increased robustness but also made the initial setup and configuration more demanding, especially in development and testing environments. From a performance and scalability perspective, the design is well-suited for horizontal scaling of the backend and independent deployment of clients, but it also depends heavily on consistent database performance and careful indexing, which had to be tuned during testing.

Constraints such as limited time, learning curves with some technologies, and the need to support both administrative dashboards and mobile workflows influenced several decisions. In some cases, planned features like more advanced analytics, offline operation for the Staff app, or more granular role definitions had to be simplified or postponed to keep the architecture manageable. There were also deviations from the initial plan, for example changing certain data structures to better reflect real-world laundry operations, simplifying some user options to reduce UI complexity, and adjusting API endpoints when the original design proved awkward for mobile usage. These experiences highlighted the importance of iterating on the architecture based on feedback, aligning design decisions with actual user scenarios, and documenting API and data model changes carefully to avoid inconsistencies.

5.2 Difficulties Encountered

During the development of LaundryPOS, several types of difficulties were encountered that affected both the architecture and implementation. On the technical side, integrating multiple technologies—such as the web framework for the Admin app, the mobile framework for the Staff app, and the Node.js backend with a database—required resolving compatibility issues, dealing with version conflicts, and understanding best practices for each platform. Implementing security features like HTTPS, environment validation, rate limiting, and RBAC introduced additional configuration challenges and sometimes caused unexpected behavior until the middleware ordering and environment variables were correctly set.

Other difficulties were related to the nature of the problem domain and evolving requirements. Modeling real laundry shop workflows (orders with multiple services, variable pricing, discounts, delivery options, and different user roles) led to increasingly complex data structures and validation logic. This complexity occasionally forced the team to revise initial database schemas, refactor controllers, or adjust how certain features were presented to users. In some cases, planned features—such as full offline support for the Staff app, more advanced reporting filters, or richer notification options—had to be scaled back or postponed because of time constraints and the additional architectural effort they would require.

These challenges influenced the course of the project and forced the use of alternative solutions in several areas. For example, some features were implemented in a simpler, more centralized way instead of introducing additional microservices, and certain user options were consolidated to reduce edge cases that were difficult to handle cleanly. The experience emphasized the importance of incremental design, frequent testing across all components (Admin, Staff, and backend), and clear documentation. Overall, the difficulties encountered provided valuable lessons about balancing ambition with maintainability, planning for integration overhead when multiple platforms are involved, and designing an architecture that can gracefully accommodate change.
